# [Case Study] 삼성계정: 500억 건의 개인정보 무중단 암호화 및 데이터 마이그레이션

## 1. 개요 및 배경

삼성계정은 18억 명의 사용자를 기반으로 24/7 대규모 트래픽을 처리하는 글로벌 서비스입니다. 클라우드 벤더 해킹이나 물리적 데이터베이스 탈취와 같은 최악의 보안 사고에 대비하여, 데이터베이스 내 모든 개인 식별 정보에 대해 컬럼 단위 암호화를 진행했습니다.

---

## 2. 암호화 설계 시 제약사항 및 해결책

### 제약사항 1: 서비스 무중단 암호화 및 마이그레이션

실시간 운영 중인 DB에 직접 암호화 작업을 수행할 경우 I/O 부하로 인한 성능 저하가 발생하며, 장애 시 복구가 매우 어렵습니다.

**[해결책]**

* **복제 DB 활용:** 운영 DB를 복제하여 오프라인 상태의 클라우드 클론 DB를 생성합니다.
* **병렬 인프라 구축:** 클론 DB의 데이터를 암호화하여 별도의 '암호화 DB'로 마이그레이션합니다.
* **DNS 기반 전환:** 내부 DNS 레이어를 추가하여 신규 암호화 서비스와 기존 서비스 간의 가중치(Weight)를 조절하며 트래픽을 안전하게 전환합니다.

### 제약사항 2: 대용량 데이터 처리 성능 (500억 건)

4개 권역에 분산된 500억 건 이상의 데이터를 24시간 발생하는 생성/수정/삭제 트래픽 속에서 빠르게 처리해야 합니다. 일반적인 배치 작업 방식은 권역당 한 달 이상의 시간이 소요되어 적용이 불가능했습니다.

**[해결책]**

* **Kafka 기반 파이프라인:** Amazon MSK와 Kafka Connect를 이용한 분산 이벤트 스트리밍 아키텍처를 구축했습니다.
* **Debezium Connector 활용:** * **Snapshot 기능:** 특정 시점의 전체 데이터를 스트리밍하여 초기 마이그레이션 속도를 확보했습니다.
* **CDC(Change Data Capture) 기능:** 데이터베이스의 변경점을 실시간으로 캡처하여 Kafka 메시지로 발행합니다.


* **데이터 추적성 확보:** 클론 DB 마이그레이션 중 발생하는 실시간 데이터는 Kafka에 쌓아두었다가, 초기 적재가 완료된 후 순차적으로 소모하여 데이터 격차를 해소했습니다.

### 제약사항 3: 인덱스 유지를 위한 스키마 변경

양방향 암호화(Encryption)는 키 로테이션과 난수 삽입으로 인해 동일한 평문이라도 암호문이 매번 달라집니다. 이 경우 해당 컬럼의 DB 인덱스가 정상 작동하지 않는 문제가 발생합니다.

**[해결책]**

* **컬럼 분리 저장:** 하나의 개인정보 데이터를 두 개의 컬럼(Hashing, Encryption)으로 나누어 저장하는 스키마 변경을 단행했습니다.
* **Hashing:** 단방향 암호화로 일정한 결과값을 생성하여 인덱스 검색 용도로 사용합니다.
* **Encryption:** 양방향 암호화로 복호화가 필요한 실제 데이터 저장 용도로 사용합니다.


* **메시지 변환:** Debezium이 발행하는 JSON 메시지 형식을 활용하여, 암호화 서비스가 원본 데이터를 읽어 스키마에 맞게 가공(Hashing + Encryption)한 후 재발행하는 구조를 설계했습니다.

### 제약사항 4: 데이터 유실 없는 롤백 플랜

단순히 트래픽을 이전 리전으로 돌리는 방식은 전환 기간 중 신규 DB에 쌓인 데이터 유실을 야기합니다.

**[해결책]**

* **역방향 파이프라인 구축:** 암호화 파이프라인과 정반대로 동작하는 '복호화 파이프라인'을 동시에 운영했습니다.
* **실시간 양방향 동기화:** 암호화 DB로 들어온 신규 데이터를 실시간으로 복호화하여 기존 DB에 동기화함으로써, 어떤 시점에 롤백하더라도 데이터 정합성이 유지되도록 설계했습니다.

---

## 3. 최종 아키텍처 요약

1. **추출:** Debezium Source Connector가 운영 DB(또는 클론)의 변경사항을 캡처하여 Kafka로 전달합니다.
2. **변환:** 암호화 서비스(Consumer)가 메시지를 가져와 D-KMS를 통해 Hashing 및 Encryption 처리를 수행합니다.
3. **적재:** 가공된 데이터를 JDBC Sink Connector가 신규 암호화 DB 스키마에 맞춰 반영합니다.
4. **동기화:** 역방향 파이프라인을 통해 기존 DB와의 정합성을 실시간으로 유지합니다.

---

## 4. 결과 및 시사점

* **보안성 강화:** 클라우드 인프라 자체가 침해받더라도 데이터 자체는 암호화되어 있어 유출 피해를 원천 차단했습니다.
* **안정성 확보:** Kafka의 분산 처리 능력과 DNS 가중치 조절을 통해 2.7M RPS가 발생하는 환경에서도 서비스 중단 없이 대규모 데이터 구조를 변경했습니다.
* **유연한 롤백:** 양방향 동기화 구조를 통해 장애 시 데이터 유실 걱정 없는 즉각적인 회복 탄력성을 구현했습니다.