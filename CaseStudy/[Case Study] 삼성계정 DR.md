## 1. 삼성 계정이란?

- 전 세계 256개국에서 60여개의 서비스와 앱을 하나로 이어주는 서비스
- 18억명 이상의 사용자를 둔 글로벌 계정 서비스

<aside>
💡

비즈니스 크리티컬 시스템이므로 높은 수준의 RTO를 가지고 있다

</aside>

- 리전 단위 장애도 극복 가능한 아키텍처 필요해 글로벌 리전 장애조치 아키텍처를 새롭게 구축함

## 2. 글로벌 리전 페일오버 아키텍처

![image1.png](../image/Service_image/삼성계정1.png)

- 리전 단위의 장애 DR을 위해 삼성계정은 여러 차례 대대적으로 아키텍처를 개선하고 기존 문제점을 해결

### 문제점 1

- 기존 2개의 리전은 대용량 트래픽을 처리해 클라우드 인프라의 한계에 달하는 리소스 사용중이었음
- 한 리전에 장애가 났을 때 다른리전으로 트래픽이 몰려도 처리하는데 한계

### 해결책 1

- 기존 EU와 US 리전에 이어 신규 AP 리전 구축
    - 트래픽 분산처리를 위한 AP 리전 구축 2024년에 완료

### 문제점 2

- 70여개의 마이크로서비스가 서로 다른 리전에 분산 배포돼 각 리전의 서비스 형상이 맞지 않았다
    - 예시) A기능은 US리전 밖에 사용할 수 없어 재해 복구에 어려움 존재

### 해결책 2

- AP리전 구축 시 각 리전에 분산돼있는 마이크로서비스들을 모든 리전에 구축하는 형상 일치화 작업 진행
- 단일 리전에서 모든 서비스와 기능을 제공할 수 있는 100% 커러비지 가진 아키텍처로 새롭게 구성

### 문제점 3

- 데이터 동기화

### 해결책 3

- 글로벌 3개 리전 필수 데이터 동기화 아키텍처 구축
- PostgerSQL 의 경우 자체 개발 동기화 파이프라인과 MSK 기반 동기화 아키텍처 구축
- DynamoDB의 경우 동기화에 Global Table 사용

<aside>
💡

Active-Active  아키텍처 고도화

</aside>

## 트래픽 전환 제어

### 검토 방안

1. 글로벌 로드 벨런서 기반의 트래픽 전환
    1. 개별 리전에 종속되지 않는 글로벌 로드 벨런서 구축
    2. 리전 장애 발생 시 로드 밸런서에서 정상 리전으로 트래픽 전환
    3. 장점 : 즉각적인 트래픽 전환으로 RTO 짧다
    4. 단점 : 대용량 트래픽을 처리하기에는 큰 비용이 든다
        1. 10년 이상의 삼성 계정 개발 기간동안 시스템이 복잡해지며 수많은 Endpoint를 가진 구조가 되어 글로벌 로드밸런서 적용해야 할 Endpoint가 너무 많아짐
2. **DNS 기반 장애 트래픽 전환**
    1. 비용 부담을 저하 & 복구작업 단순화를 위해 DNS 기반의 트래픽 전환 방식 선택
    2. AWS Route 53을 활용해 리전 단위 장애 발생 시 서비스 도메인의 Endpoint 를 정상 리전의 Endpoint로 전환
    
    <aside>
    💡
    
    큰 문제점 발생 : Route53 은 DNS Record 의 추가와 변경을 처리하는 Control plane 이 US 리전에만 구축되어 있어 US 리전이나 Control plane에 장애가 발생할 경우 원하는 대로 DNS Record 를 추가하거나 변경할 수 없으며 Data plane 의 사전 정의된 기능만 동작 가능함
    
    </aside>
    
    - 한마디로 US 리전 의존도가 너무 커진다
    - Route53의 Control plane 이 동작하지 않으면 장애 시나리오에서 트래픽 전환이 필요해도 DNS Record 를 변경하지 못해 장애 트래픽 전환 제어가 불가능
    
    ![image2.png](../image/Service_image/삼성계정2.png)
    

### 리전 단위 장애 복구 방식

- Control plane 문제 해결 솔루션 - Route 53 Application Recovery Controller(ARC)
- Route53 ARC 는 Control plane 에 장애가 발생하더라도 Data plane에 미리 준비한 Primary 와 Standby 라우팅 제어 세트가 Health Check 를 통해 장애 감지 시 트래픽 제어 기능 제공
- 장애 복구는 셀 단위로 이뤄지는데 셀이란 서비스의 독립적인 장애조치 단위를 포함하는 Silo 를 의미
- 삼성 계정은 리전 단위의 장애를 복구할 수 있도록 셀을 리전으로 구성했고 각 리전은 독립적인 서비스가 가능한 Active-Active 형태로 구축함
- 결과적으로 삼성 계정은 Route53 ARC 의 고가용성 기능을 활용해 리전 단위의 장애조치 아키텍처를 확보할 수 있었음

## 3. 운영환경 모의 장애 훈련

1. 검증환경에서 글로벌 장애조치 아키텍처의 기능 점검하는 기능 검증
    1. 전체 2% 수준의 트래픽 전환으로 기능 점검
    2. 삼성 계정에는 내부 URL 이 많아 트래픽 전환 간에 문제가 발생할 수 있는데, 기능 검증 과정에서 누락된 URL 설정을 미리 확인하고 조치할 수 있었음
2. 장애 복구 트래픽의 부하를 점검하는 부하 검증 진행
    1. 전체 10% 와 50% 두 단계로 나누어 수행
    2. 서비스와 EKS, DB 를 보함한 전 영역의
    3. 인증 토큰 재발급 트래픽과 리전간 호출 급증 등 아키텍처 개선이 필요한 부분 추가로 확인하고 개선
    4. 실제 운영환경에서 모의 장애 훈련 진행

### 1차 모의 장애 훈련

- 5분 내에 90%의 주요 트래픽이 전환되었고 시스템이나 사용자 VOC(Voice of Consumer) 없이 성공적으로 훈련 완료
- 하지만 개선사항 존재

![image3.png](../image/Service_image/삼성계정3.png)

[MTTR 10분 이상]

- MTTR이란?
    
    Mean Time To Repair
    
    - 시스템에 문제가 생겨서 서비스가 중단된 시점부터 다시 정상적으로 돌아올 때까지 걸린 시간의 평균
    - 총 장애 복구 시간 합계 / 장애 발생 횟수
    
    MTBF = Mean Time Between Failures
    
    - 고장 안나고 버티는 시간
    
    솔루션 아키텍트 관점에서 시스템이 아예 안꺼지게 MTBF를 늘리는것도 중요하지만 장애가 났을 때 Self-healing 구조를 설계해 MTTR을 최소화 하는것이 중요
    
- 예상했던 일부 잔여 트래픽이 10분 이상 존재하는것을 확인
    - 붉게 칠해진 롱테일 영역이 잔여 트래픽
    - 클라이언트 영역의 DNS cashe가 장애조치 전 서버의 IP를 캐싱하고 있기 때문에 발생
- 삼성계정의 RTO 는 장애조치를 통해 5분 내에 99%의 트래픽을 정상 처리해내는 것이지만 90%라는 한계 존재

![image4.png](../image/Service_image/삼성계정4.png)

사용자 네트워크 분석

- 잔여 트래픽 분석 결과 사용자 영역의 네트워크 경험을 개선해야 함
    - 일반적으로 네트워크 응답 시간은
        1. 도메인 주소를 질의해 대상 서버의 IP로 변환되는 과정
            1. DNS서버에서 IP를 리졸빙하고 반환하는 과정
        2. 대상 서버와의 TCP 연결
            1. 3way handshake (SYN, SYN+ACK, ACK)
        3. SSL연결
            1. HTTPS 보안을 위한 비대칭키, 대칭키 암호화
            - TLS 핸드쉐이크 단계
                
                ![image5.png](../image/Service_image/삼성계정5.png)
                
                1. Client Hello :  암호 방식과 암호 만들때 쓸 랜덤 값 포함 전송
                2. Server Hello : 암호 방식 선택, 서버 랜덤 값 전송
                3. Certificate : 서버 인증서(CA) 전송(인증서 안에는 서버의 공개 키 들어있음)
                4. Server Key Exchange/ Hello Done : 서버 인사 끝
                5. Client Key Exchange : 서버의 공개키로 클라이언트가 만든 새로운 랜덤 값을 암호화 해서 전송 (이 값은 서버의 개인키로만 풀 수 있어서 안전, 양쪽은 각자 가진 랜덤 값을 조합해 대칭 키를 만든다)
                6. Change Cipher Spec/ Finished : 클라이언트 준비 끝, 암호화 확인
                7. Change Cipher Spec / Finished : 서버 준비 끝 TLS 연결 수립
        4. 서버 처리 후 데이터가 클라이언트에 전송되는 과정으로 구성됨
            1. 실제 컨텐츠 전송
- 전세계의 요청을 실제로 글로벌 리전에서 수행하다 보니 모든 사용자의 연결이 빠르진 않았음
- 분석결과로는 TCP연결과 TLS 핸드쉐이크 과정에서 특히 많은 시간이 소요됨

### 아키텍처 개선

![image6.png](../image/Service_image/삼성계정6.png)

잔여 트래픽 처리의 주요 원인은 클라이언트의 DNS cache 처리 문제

- Client의 OS 나 네트워크 구성에는 DNS 에서 수신된 TTL을 재정의 하는 자체 캐싱 메커니즘이 있을 수 있다.
    - 1분 TTL 을 갖는 서비스 도메인의 IP를 변경해도 일부 클라이언트는 10분 넘게 갱신이 안될 수 있다.
- 사용자와 실제 서버 사이를 First mile, Middle mile, Last mile 3가지 세그먼트로 나뉘는데
    - middle mile 가 가장 문제가 되는 구간
    - 이 구간은 ISP가 관리하는 인터넷 영역으로 가장 방대하고 거리가 길어 많은 네트워크 오류가 존재해 잘못된 라우팅이 발생하기도 함

### 해결책

- AWS CloudFront 를 활용해 Edge location 이 캐싱되게 한다.
- 사용자는 삼성계정 서버의 IP가 아닌 엣지 로케이션에 연결되어 삼성계정 서버의 IP 가 변경되어도 client cache 문제가 발생하지 않음
- middle mile을 통과하지 않고 사용자 위치에 가까운 엣지 로케이션으로 연결돼 네트워크 커넥션 오버헤드가 현저히 감소
- CDN 사업자의 전용 백본 망으로 통신하여 Middle mile public 망으로 통과해 origin 서버에 연결되는 것보다 훨씬 속도가 빠름

### 2차 모의 장애 훈련

![image7.png](../image/Service_image/삼성계정7.png)

롱테일 현상이 사라지고 3분 내에 99% 이상의 트래픽 전환

- CloudFront 적용 효과로 엣지 로케이션 연결설정에 필요한 왕복 시간이 현저히 감소했고 CloudFront의 Origin에 대한 지속적인 TCP 연결 등으로 전체 네트워크 연결 속도가 65% 이상 개선됨